{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook implements Assignment 2 of course on Trustworthy Machine Learning."
      ],
      "metadata": {
        "id": "z_Zf1yvu5iZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaVZ6EuB63fr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b380121-438e-49ff-ee4c-ce488fcc0856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM5Ss0Y5Evx2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import ToPILImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1WkeBgO6tLU",
        "outputId": "cfc828d0-8e7d-4276-af41-49030f27f7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwd:  /content\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Do install:\n",
        "# conda install onnx\n",
        "# conda install onnxruntime\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import json\n",
        "import io\n",
        "import sys\n",
        "import base64\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Tuple\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "cwd = os.getcwd()\n",
        "print('cwd: ', cwd)\n",
        "\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "\n",
        "        self.ids = []\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
        "        id_ = self.ids[index]\n",
        "        img = self.imgs[index]\n",
        "        if not self.transform is None:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[index]\n",
        "        return id_, img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH9BPBfx6tLV",
        "outputId": "a81cac45-2cff-44f0-a327-04907afad9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'seed': 96417488, 'port': '9060'}\n"
          ]
        }
      ],
      "source": [
        "### REQUESTING NEW API ###\n",
        "TOKEN = \"92593601\" # to be changed according to your token (given to you for the assignments)\n",
        "\n",
        "response = requests.get(\"http://34.71.138.79:9090\" + \"/stealing_launch\", headers={\"token\": TOKEN})\n",
        "answer = response.json()\n",
        "\n",
        "print(answer)  # {\"seed\": \"SEED\", \"port\": PORT}\n",
        "if 'detail' in answer:\n",
        "    sys.exit(1)\n",
        "\n",
        "# save the values\n",
        "SEED = str(answer['seed'])\n",
        "PORT = str(answer['port'])\n",
        "\n",
        "# SEED = \"1868949\"\n",
        "# PORT = \"9002\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining transformations to the dataset"
      ],
      "metadata": {
        "id": "hi9SA9aj52_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDT8qi63EhfC"
      },
      "outputs": [],
      "source": [
        "mean = [0.2980, 0.2962, 0.2987]\n",
        "std = [0.2886, 0.2875, 0.2889]\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Dataset and applying transformations"
      ],
      "metadata": {
        "id": "wD5Ma8xi6EO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQlmU06ME58F"
      },
      "outputs": [],
      "source": [
        "dataset = torch.load(\"/content/ModelStealingPub.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSDWhfPPE9uj"
      },
      "outputs": [],
      "source": [
        "dataset.transform = transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gizvvReToXM"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeWYGqnA6tLW"
      },
      "outputs": [],
      "source": [
        "### QUERYING THE API ###\n",
        "\n",
        "def model_stealing(images, port):\n",
        "    endpoint = \"/query\"\n",
        "    url = f\"http://34.71.138.79:{port}\" + endpoint\n",
        "    image_data = []\n",
        "    for img in images:\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        img.save(img_byte_arr, format='PNG')\n",
        "        img_byte_arr.seek(0)\n",
        "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
        "        image_data.append(img_base64)\n",
        "\n",
        "    payload = json.dumps(image_data)\n",
        "    response = requests.get(url, files={\"file\": payload}, headers={\"token\": \"92593601\"})\n",
        "    if response.status_code == 200:\n",
        "        representation = response.json()[\"representations\"]\n",
        "        return representation\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Model stealing failed. Code: {response.status_code}, content: {response.json()}\"\n",
        "        )\n",
        "\n",
        "out = model_stealing([dataset.imgs[idx] for idx in np.random.permutation(1000)], port=\"9060\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8jJdPJL6tLW",
        "outputId": "79c134b7-46a7-4e77-b104-0f6c55b6af48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "1024\n",
            "-0.6153451204299927\n"
          ]
        }
      ],
      "source": [
        "# 1000 representations in a list\n",
        "print(len(out))\n",
        "\n",
        "# representation 1\n",
        "print(len(out[0]))\n",
        "\n",
        "# first element in the representation\n",
        "print(out[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGDAvvQq6tLX",
        "outputId": "c6052209-b888-46aa-9d1f-87b0ae38b4db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n"
          ]
        }
      ],
      "source": [
        "# Store the output in a file.\n",
        "# Be careful to store all the outputs from the API since the number of queries is limited.\n",
        "with open('out84.pickle', 'wb') as handle:\n",
        "    pickle.dump(out, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Restore the output from the file.\n",
        "with open('out84.pickle', 'rb') as handle:\n",
        "    out = pickle.load(handle)\n",
        "\n",
        "print(len(out))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing representations obtained from victim encoder"
      ],
      "metadata": {
        "id": "UIaOSIcS6J2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K286Wp6yLPrc"
      },
      "outputs": [],
      "source": [
        "victim_representations = []\n",
        "\n",
        "for i in range(1, 85):\n",
        "    with open(f'/content/out{i}.pickle', 'rb') as handle:\n",
        "        victim_representations.extend(pickle.load(handle))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPsIgE6rK2kA"
      },
      "outputs": [],
      "source": [
        "with open('victim_representations84.pickle', 'wb') as handle:\n",
        "    pickle.dump(victim_representations, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the stolen model architecture and creating an instance"
      ],
      "metadata": {
        "id": "BYbgYahJDAXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOzMS9aANyr3"
      },
      "outputs": [],
      "source": [
        "class StolenEncoder(nn.Module):\n",
        "    def __init__(self, input_channels, input_height, input_width):\n",
        "        super(StolenEncoder, self).__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.input_height = input_height\n",
        "        self.input_width = input_width\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * (input_height // 4) * (input_width // 4), 1024)  # Adjusted for 32x32 input\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pJrBHaSN47b"
      },
      "outputs": [],
      "source": [
        "input_channels = 3\n",
        "input_height = 32\n",
        "input_width = 32\n",
        "\n",
        "model = StolenEncoder(input_channels, input_height, input_width).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueRpvriLREOD"
      },
      "outputs": [],
      "source": [
        "victim_representations = torch.tensor(victim_representations).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjztPMBTSd7g"
      },
      "outputs": [],
      "source": [
        "loader = DataLoader(dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xbUg-zMQIcU"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    for i, (batch_ids, batch_images, batch_labels) in enumerate(loader):\n",
        "        batch_images = [(img.repeat(3, 1, 1) if img.size(0) == 1 else img) for img in batch_images]\n",
        "        batch_images = torch.stack(batch_images).to(device)\n",
        "\n",
        "        # to handle the mismatch of the length of the stolen and victim encoder's representations\n",
        "        batch_size = batch_images.size(0)\n",
        "        start_idx = i * loader.batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        if end_idx > len(victim_representations):\n",
        "            end_idx = len(victim_representations)\n",
        "            batch_victim_reps = victim_representations[start_idx:end_idx]\n",
        "            batch_images = batch_images[:end_idx-start_idx]\n",
        "        else:\n",
        "            batch_victim_reps = victim_representations[start_idx:end_idx]\n",
        "\n",
        "        if len(batch_victim_reps) != batch_size:\n",
        "            print(f\"Skipped batch {i+1} because of mismatch between images ({batch_size}) and victim representations ({len(batch_victim_reps)}).\")\n",
        "            continue\n",
        "\n",
        "        stolen_reps = model(batch_images)\n",
        "        loss = criterion(stolen_reps, batch_victim_reps)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Batch [{i+1}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "torch.save(model, 'stolen_encoder.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brOmKMzK6tLX",
        "outputId": "58595d00-b095-4ef8-bfe2-4a0762061482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'L2': 11.385514259338379}\n"
          ]
        }
      ],
      "source": [
        "#### SUBMISSION ####\n",
        "\n",
        "path = 'dummy_submission3.onnx'\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    torch.randn(1, 3, 32, 32),\n",
        "    path,\n",
        "    export_params=True,\n",
        "    input_names=[\"x\"],\n",
        ")\n",
        "\n",
        "#### Tests ####\n",
        "\n",
        "# (these are being ran on the eval endpoint for every submission)\n",
        "with open(path, \"rb\") as f:\n",
        "    model = f.read()\n",
        "    try:\n",
        "        stolen_model = ort.InferenceSession(model)\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Invalid model, {e=}\")\n",
        "    try:\n",
        "        out = stolen_model.run(\n",
        "            None, {\"x\": np.random.randn(1, 3, 32, 32).astype(np.float32)}\n",
        "        )[0][0]\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Some issue with the input, {e=}\")\n",
        "    assert out.shape == (1024,), \"Invalid output shape\"\n",
        "\n",
        "# Send the model to the server\n",
        "response = requests.post(\"http://34.71.138.79:9090/stealing\", files={\"file\": open(path, \"rb\")}, headers={\"token\": TOKEN, \"seed\": SEED})\n",
        "print(response.json())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}